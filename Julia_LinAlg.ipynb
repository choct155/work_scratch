{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QE](https://avatars3.githubusercontent.com/u/8703060?v=3&s=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra in Julia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an intro to the linear algebra tools that will be used later in the QE tutorials.  There is overlap with some of the preceding intro to Julia walkthroughs.  Some this material will be skipped.\n",
    "\n",
    "To start, the inner (or dot) product is defined as follows:\n",
    "\n",
    "$x'y := \\sum_{i=1}^n x_i y_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [3,1,9,3,5,10,9,1,7,5]\n",
      "y: [7,5,1,2,6,8,5,3,5,8]\n",
      "x ̇⋅ y: 274\n"
     ]
    }
   ],
   "source": [
    "#Define two arrays\n",
    "x=rand(1:10,10)\n",
    "y=rand(1:10,10)\n",
    "\n",
    "println(string(\"x: \",x))\n",
    "println(string(\"y: \",y))\n",
    "println(string(\"x ̇⋅ y: \",dot(x,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *norm* of the vector is just the distance from the origin.  It can be found easily with the aid of the Pythagorean Theorem.\n",
    "\n",
    "$||x|| := \\sqrt{x'x} := (\\sum_{i=1}^n x_i^2)^{\\frac{1}{2}}$\n",
    "\n",
    "The distance between to point $x$ and $y$ is just $||x-y||$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.519221295943133\n",
      "19.519221295943137\n"
     ]
    }
   ],
   "source": [
    "#Use intrinsic norm function\n",
    "println(norm(x))\n",
    "\n",
    "#Check with manual calculation\n",
    "println(sqrt(sum(x.^2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of vectors $A$, the span of $A$ is the set of all linear combinations of the vectors in $A$.  One may think of it as the infinite hyperplane in the given dimensions.  For example, observe the span of $A = \\{a_1,a_2\\}$ in $\\mathbb{R}^3$..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2Dspan](http://quant-econ.net/_images/3dvec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead defined $A$ as $A = \\{e_1,e_2,e_3\\}$ where the three vectors are the *canonical basis vectors* of $\\mathbb{R}^3$, the span would be all of three dimensional space.  However, if $A = \\{e_1,e_2,e_1+e_2\\}$, the third dimension is unused.  Therefore, the span is again just a plane.  To see why this is true analytically, consider the following vectors:\n",
    "\n",
    "$e_1 = \\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix},$\n",
    "$e_2 = \\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix},$\n",
    "$e_1 + e_2 = \\begin{bmatrix}1\\\\1\\\\0\\end{bmatrix}$\n",
    "\n",
    "With these inputs, we have the following matrix...\n",
    "\n",
    "$A = \\begin{bmatrix}\n",
    "     1 & 0 & 1\\\\\n",
    "     0 & 1 & 1\\\\\n",
    "     0 & 0 & 0\\\\\n",
    "     \\end{bmatrix}$  \n",
    "  \n",
    "...and we must solve for $y = (y_1, y_2, y_3)$.  Using $c_n$ as the coefficient variables, we are faced with the following system of equations:\n",
    "\n",
    "$c_1*(1) + c_2*(0) + c_3*(1) = y_1 = c_1 + c_3\\\\\n",
    "c_1*(0) + c_2*(1) + c_3*(1) = y_2 = c_2 + c_3\\\\\n",
    "c_1*(0) + c_2*(0) + c_3*(0) = y_3 = 0$\n",
    "\n",
    "As can be seen, $y_3=0$, so the vector space does not span all of $\\mathbb{R}^3$.  Rather, it spans $\\mathbb{R}^2$.  This concept of span is one useful path to the idea of linear dependence.  Vectors that do not extend the span of a vector space are linear combinations of the vectors that do.  $e_3$ fits this description, and indeed it was explicitly defined as a linear combination of $e_1$ and $e_2$.  If we were add a vector, $a_3$ to the system depicted in Figure 1, it must lie off the plane formed by the span of $A = \\{a_1,a_2\\}$ to keep the vector space linearly independent.  If $a_3$ lies on that plane, the vector space becomes linearly dependent.  To use terms that resonate more with me, for a new vector to be linearly independent of the existing vectors in a space, it must *extend the dimensionality of the span*.\n",
    "\n",
    "A corollary to this relationship between spans and linear independence is the uniqueness of each linear combination of the vectors in the space.  In other words, if $A$ is linearly independent and $y=\\beta_1 a_1 + ... \\beta_k a_k$, there is no sequence of weights $\\gamma_1 + .... \\gamma_k$ that can produce the same vector $y$.\n",
    "\n",
    "As we well know, the multiplication of matrices just generalizes the inner (or dot) product operation.  In Julia, matrices are straightforward to create.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2\n",
      " 3 4]\n",
      "[1 2\n",
      " 3 4]\n",
      "[1 2\n",
      " 3 4]\n",
      "(2,2)\n"
     ]
    }
   ],
   "source": [
    "A=[1 2\n",
    "   3 4]\n",
    "\n",
    "println(A)\n",
    "\n",
    "B=[1 2;3 4]\n",
    "println(B)\n",
    "\n",
    "C=reshape([1 2 3 4],(2,2))' #Note the transpose\n",
    "println(C)\n",
    "println(size(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication (inner product) leverages the `*` operator, while element-wise multiplication uses the `.*` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 10\n",
      " 15 22]\n",
      "[1 4\n",
      " 9 16]\n"
     ]
    }
   ],
   "source": [
    "println(A*B)\n",
    "println(A.*B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have the following system of equations:  $y=Ax$.  This would be akin to our earlier system...\n",
    "\n",
    "$\\underbrace{\\begin{bmatrix} 1 & 0 & 1\\\\ 0 & 1 & 1\\\\ 0 & 0 & 0 \\end{bmatrix}}_{A} * \\underbrace{\\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3 \\end{bmatrix}}_{c} = \\underbrace{\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{bmatrix}}_{y}$  \n",
    "\n",
    "...except we swapped $x$ for $c$.  A natural question would be, given $A$ and $y$, can we solve for $x$?  This is only possible if $y$ is in the range of possible values given the linear combinations in $A$.  Said differently, is $y$ in the range of $f(x)=Ax$?  In this context, the range is the span of the linearly independent subspace of $A$. In other words, if $y \\in \\mathbb{R}^n$ and the span of $f(x)=Ax$ is $\\mathbb{R}^n$ then a solution vector $x$ will exist.  Even better, it will be a unique solution.\n",
    "\n",
    "When the number of rows $n$ in $A$ exceeds the number of columns $k$, existence of a solution is doubtful.  Why is that?  If $A$ is $n \\times k$, then $y$ is $n \\times 1$ and $x$ is $k \\times 1$.  In other words, $y \\in \\mathbb{R}^n$ while $x \\in \\mathbb{R}^k$, so the span of possible solutions is of lower dimensionality than the sought after vector.  Imagine trying to use a plane for the solution when that vector can be anywhere in 3D space.  In this event, the \"solution\" is an approximation seeking to minimize $||y-Ax||$.\n",
    "\n",
    "If the number of rows $n$ in $A$ is less than the number of columns $k$, that means the number of equations ($n$) is less than the number of unknowns ($k$).  Existence may still be preserved, but it won't be unique.  Many $x$ vectors will provide a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.7",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
